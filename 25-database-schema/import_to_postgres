#!/bin/env python


from numpy import dtype
from glob import glob
import sys
import json
import pandas as pd
sys.path.insert(0, '.')
from pg_utilities import VenuesReader, MemberReader, GroupReader, GroupMemberReader, EventReader, RsvpReaderCOLUMNS, EventCOLUMNS
import  psycopg2, psycopg2.extras
from collections import Counter

data_dir = "../10-data/"

db_conn = psycopg2.connect("dbname='infovis_meetup'")
db_conn.autocommit = True
db_cursor = db_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

from sqlalchemy import create_engine
engine = create_engine('postgresql+psycopg2:///infovis_meetup')

all_groups = [ path.replace("%s/events_updated/" % data_dir, "").replace(".json","") for path in glob("%s/events_updated/*.json" % data_dir) ]
print "importing for %d groups" % len(all_groups)


if False:
  for df in VenuesReader( all_groups , do_max = True):
    if not 'id_venue' in df.columns:
      print "skipping venue df with len=%d, columns %s" % ( len(df.index), df.columns.values) 
    else:
      df.to_sql('venues', engine, if_exists = 'append', index = False)

  # manual fixes:  lat + lon cannot be null in python dataframes, have to find nulls again in postgres:    
  db_cursor.execute("update venues set lat=null,lon=null where lat=0.0 and lon=0.0")
  db_cursor.execute("select count(*) as c from venues")
  print "%d venues inserted" % db_cursor.fetchone()['c']


if False:
  db_cursor.execute("delete from members")
  for df in MemberReader( all_groups, do_max = True):
    if 'status' in df.columns:
      del( df['status'] )
    if not 'id_member' in df.columns:
      print "skipping member df with len=%d, columns %s" % ( len(df.index), df.columns.values) 
    else:
      df.to_sql('members', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from members")
  m1 = db_cursor.fetchone()['c']
  print "%d members inserted" % m1

if False: # organizers from sub-json
  db_cursor.execute("select count(*) as c from members")
  m1 = db_cursor.fetchone()['c']
  orgas = json.load(open(data_dir + "organizers.json"))
  for o in orgas:
    db_cursor.execute("""INSERT INTO members (id_member) 
                          SELECT %(id)s
                          WHERE NOT EXISTS (
                            SELECT 1 FROM members WHERE id_member=%(id)s
                          )""", { 'id': str( o['member_id'] )} )
  db_cursor.execute("select count(*) as c from members")
  m2 = db_cursor.fetchone()['c']
  print "%d more organizser inserted" % (m2 - m1)
  print "%d members in all" % m2


if False:
  db_cursor.execute("delete from groups")
  for df in GroupReader( do_max = True):
    if not 'id_group' in df.columns or not 'member_id_organizer' in df.columns:
      print "skipping group df with len=%d, columns %s" % ( len(df.index), df.columns.values) 
    else:
      df.rename(columns = {'member_id_organizer': 'id_organizer', 'members': 'no_members'}, inplace=True)
      df.to_sql('groups', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from groups")
  print "%d groups inserted" % db_cursor.fetchone()['c']


if False:
  db_cursor.execute("delete from is_member_of")
  for df in GroupMemberReader( all_groups, do_max = True):
    if 'status' in df.columns:
      del( df['status'] )
    if  not ('id_member' in df.columns) or not ('id_group' in df.columns):
      print "skipping df with len=%d, columns %s" % ( len(df.index), df.columns.values) 
    else:
      df.to_sql('is_member_of', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from is_member_of")
  print "%d is_member_of records inserted" % db_cursor.fetchone()['c']


if False:
  db_cursor.execute("delete from events")
  for df in EventReader( all_groups, do_max = True):
    if  not ('id_event' in df.columns):
      print "skipping event df with len=%d, columns %s" % ( len(df.index), df.columns.values ) 
    else:
      df.to_sql('events', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from events")
  print "%d event inserted" % db_cursor.fetchone()['c']


#    'created_wday': dtype('int64'),
#    'headcount': dtype('int64'),
#    'id_event': dtype('int64'),
#    'id_group': dtype('int64'),
#    'id_venue': dtype('int64'),
#    'maybe_rsvp_count': dtype('int64'),
#    'time_wday': dtype('int64'),
#    'updated_wday': dtype('int64'),
#    'updated': dtype('int64'),
#    'utc_offset': dtype('int64'),
#    'waitlist_count': dtype('int64'),
#    'yes_rsvp_count': dtype('int64'),

if True:
  db_cursor.execute("delete from events")
  cols = EventCOLUMNS
  cols['created_wday'] = dtype('O')
  cols['id_rsvp'] = dtype('O')
  del(cols['created'])
  del(cols['time'])
  # del(cols['updated'])
  reader = pd.read_csv(data_dir + 'events.csv', iterator=True, chunksize=1, dtype = cols, parse_dates = ['created', 'time'])
  for df in reader:
    col='updated'
    df[col] = pd.to_datetime(df[col],unit='ms') 
    df[col + "_wday"] = df[col].apply(lambda x: x.weekday())

    del(df["Unnamed: 0"])
    del(df["name_venue"])
    del(df["phone_venue"])
    del(df["repinned_venue"])
    del(df["address_1_venue"])
    del(df["address_2_venue"])
    del(df["city_venue"])
    del(df["state_venue"])
    del(df["country_venue"])
    del(df["zip_venue"])
    del(df["lat_venue"])
    del(df["lon_venue"])
    del(df["lat_group"])
    del(df["lon_group"])
    del(df["name_group"])
    del(df["urlname_group"])
    del(df["group"])
    del(df["id"])
    del(df["id_main"])
    del(df["id_rsvp"])
    del(df["who_group"])
    del(df["created_group"])
    del(df["created_group_wday"])
    del(df["join_mode_group"])
    del(df["filename"])
    df.rename(columns = {'visibility': 'venue_visibility', 'created_main': 'created', 'name_main':'name'}, inplace=True)
    df.to_sql('events', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from events")
  print "%d events inserted" % db_cursor.fetchone()['c']




if False:
  db_cursor.execute("delete from rsvps")
  used_ids = Counter()
  cols = RsvpReaderCOLUMNS
  del(cols['created'])
  del(cols['mtime'])
  reader = pd.read_csv(data_dir + 'rsvps.csv', iterator=True, chunksize=50000, dtype = RsvpReaderCOLUMNS, parse_dates = ['created', 'mtime'])
  for df in reader:
    del(df['Unnamed: 0'])
    del(df['name_member'])
    df.drop_duplicates(subset = ['rsvp_id'], inplace = True)
    df['watching'] = df['watching'].astype('bool')
    df.to_sql('rsvps', engine, if_exists = 'append', index = False)
  db_cursor.execute("select count(*) as c from rsvps")
  print "%d rsvps inserted" % db_cursor.fetchone()['c']


